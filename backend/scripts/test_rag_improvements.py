#!/usr/bin/env python3
"""
Script de test pour v√©rifier les am√©liorations du RAG.
Teste l'extraction de pages, la d√©tection de sections, et la validation des citations.
"""
import sys
import os

# Ajouter le r√©pertoire backend au path
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))

from app.core.database import SessionLocal
from app.models.document import Document, DocumentChunk
from app.services.text_extractor import TextExtractor
from app.services.document_processor import DocumentProcessor
from sqlalchemy import func


def test_page_extraction():
    """Teste l'extraction des num√©ros de pages r√©els."""
    print("\n" + "="*80)
    print("üìÑ TEST 1: EXTRACTION DES NUM√âROS DE PAGE")
    print("="*80)
    
    db = SessionLocal()
    
    # Prendre un document PDF
    doc = db.query(Document).filter(Document.file_type == 'pdf').first()
    
    if not doc:
        print("‚ùå Aucun document PDF trouv√©")
        db.close()
        return
    
    print(f"\nüìÅ Document: {doc.name}")
    print(f"   Fichier: {doc.file_path}")
    
    # Extraire les pages
    extractor = TextExtractor()
    import asyncio
    pages = asyncio.run(extractor.extract_text_with_pages(doc.file_path, doc.file_type))
    
    print(f"\n‚úÖ {len(pages)} pages extraites")
    print("\nExemples de mapping:")
    print("-" * 80)
    print(f"{'Position physique':<20} {'Page extraite':<20} {'Extrait?':<20}")
    print("-" * 80)
    
    for page_info in pages[:10]:  # Afficher les 10 premi√®res
        physical = page_info.get('physical_position', '?')
        real_page = page_info.get('page', '?')
        extracted = "‚úÖ Oui" if page_info.get('page_extracted', False) else "‚ùå Non (physique)"
        
        print(f"{physical:<20} {real_page:<20} {extracted:<20}")
    
    if len(pages) > 10:
        print(f"... et {len(pages) - 10} autres pages")
    
    db.close()


def test_section_detection():
    """Teste la d√©tection des titres de sections."""
    print("\n" + "="*80)
    print("üìë TEST 2: D√âTECTION DES SECTIONS")
    print("="*80)
    
    db = SessionLocal()
    
    # Compter les chunks avec sections
    total_chunks = db.query(DocumentChunk).count()
    chunks_with_section = db.query(DocumentChunk).filter(
        DocumentChunk.chunk_metadata['section'].astext != None
    ).count()
    
    percentage = (chunks_with_section / total_chunks * 100) if total_chunks > 0 else 0
    
    print(f"\nüìä Statistiques:")
    print(f"   Total de chunks: {total_chunks}")
    print(f"   Chunks avec section: {chunks_with_section}")
    print(f"   Pourcentage: {percentage:.1f}%")
    
    # Objectif: 80%+
    if percentage >= 80:
        print(f"   ‚úÖ Excellent! (objectif: 80%)")
    elif percentage >= 50:
        print(f"   ‚ö†Ô∏è  Acceptable (objectif: 80%)")
    else:
        print(f"   ‚ùå Insuffisant (objectif: 80%)")
    
    # Afficher quelques exemples
    print("\nüìù Exemples de sections d√©tect√©es:")
    print("-" * 80)
    
    chunks_with_sections = db.query(DocumentChunk).filter(
        DocumentChunk.chunk_metadata['section'].astext != None
    ).limit(10).all()
    
    for chunk in chunks_with_sections:
        section = chunk.chunk_metadata.get('section', 'N/A')
        doc_name = chunk.chunk_metadata.get('document_name', 'Unknown')
        page = chunk.chunk_metadata.get('page', '?')
        
        print(f"\nüìÑ {doc_name}, p.{page}")
        print(f"   Section: {section[:100]}")
    
    db.close()


def test_chunk_quality():
    """Teste la qualit√© du chunking."""
    print("\n" + "="*80)
    print("‚úÇÔ∏è  TEST 3: QUALIT√â DU CHUNKING")
    print("="*80)
    
    db = SessionLocal()
    
    # Statistiques sur les chunks
    chunks = db.query(DocumentChunk).all()
    
    if not chunks:
        print("‚ùå Aucun chunk trouv√©")
        db.close()
        return
    
    # Calculer des m√©triques
    token_counts = [chunk.token_count for chunk in chunks]
    avg_tokens = sum(token_counts) / len(token_counts)
    min_tokens = min(token_counts)
    max_tokens = max(token_counts)
    
    print(f"\nüìä Statistiques de chunking:")
    print(f"   Nombre de chunks: {len(chunks)}")
    print(f"   Tokens moyens: {avg_tokens:.0f}")
    print(f"   Tokens min: {min_tokens}")
    print(f"   Tokens max: {max_tokens}")
    
    # V√©rifier si les chunks commencent bien (pas au milieu d'une phrase)
    chunks_starting_lowercase = 0
    chunks_ending_incomplete = 0
    
    for chunk in chunks[:100]:  # √âchantillon de 100
        content = chunk.content.strip()
        if content and content[0].islower():
            chunks_starting_lowercase += 1
        if content and content[-1] not in '.!?\n':
            chunks_ending_incomplete += 1
    
    print(f"\nüìã Qualit√© des fronti√®res (√©chantillon de 100):")
    print(f"   Chunks commen√ßant en minuscule: {chunks_starting_lowercase} (objectif: <5)")
    print(f"   Chunks finissant incomplets: {chunks_ending_incomplete} (objectif: <10)")
    
    if chunks_starting_lowercase < 5:
        print("   ‚úÖ Excellent d√©but de chunks")
    else:
        print("   ‚ö†Ô∏è  Beaucoup de chunks commencent au milieu d'une phrase")
    
    if chunks_ending_incomplete < 10:
        print("   ‚úÖ Bonnes fins de chunks")
    else:
        print("   ‚ö†Ô∏è  Beaucoup de chunks finissent au milieu d'une phrase")
    
    db.close()


def test_metadata_enrichment():
    """Teste l'enrichissement des m√©tadonn√©es."""
    print("\n" + "="*80)
    print("üè∑Ô∏è  TEST 4: ENRICHISSEMENT DES M√âTADONN√âES")
    print("="*80)
    
    db = SessionLocal()
    
    # V√©rifier les m√©tadonn√©es enrichies
    chunk = db.query(DocumentChunk).first()
    
    if not chunk:
        print("‚ùå Aucun chunk trouv√©")
        db.close()
        return
    
    metadata = chunk.chunk_metadata or {}
    
    print(f"\nüìã M√©tadonn√©es disponibles:")
    print("-" * 80)
    
    fields = [
        ('document_name', 'Nom du document'),
        ('document_type', 'Type de document'),
        ('page', 'Num√©ro de page'),
        ('page_extracted', 'Page extraite du contenu?'),
        ('physical_position', 'Position physique dans PDF'),
        ('section', 'Titre de section')
    ]
    
    for field, description in fields:
        value = metadata.get(field)
        status = "‚úÖ" if value is not None else "‚ùå"
        print(f"{status} {description:<30} : {value}")
    
    print("\nüìÑ Exemple complet de m√©tadonn√©es:")
    print("-" * 80)
    import json
    print(json.dumps(metadata, indent=2, ensure_ascii=False))
    
    db.close()


def print_summary():
    """Affiche un r√©sum√© des am√©liorations."""
    print("\n" + "="*80)
    print("üìä R√âSUM√â DES AM√âLIORATIONS")
    print("="*80)
    
    print("""
‚úÖ Phase 1: Extraction de pages r√©elles
   - Extraction depuis le contenu du PDF (footer/header)
   - Patterns: "Page X", "X/Y", "- X -", "p. X"
   - Fallback: position physique si non trouv√©
   - M√©tadonn√©e: page_extracted (True/False)

‚úÖ Phase 2: D√©tection de sections am√©lior√©e
   - Patterns √©tendus: ARTICLE, CHAPITRE, SECTION, ANNEXE, etc.
   - D√©tection des num√©rotations: X.Y.Z, I.II.III
   - D√©tection des titres en majuscules
   - Objectif: 80%+ des chunks avec section

‚úÖ Phase 3: Chunking optimis√©
   - Overlap augment√©: 150 ‚Üí 200 caract√®res (19%)
   - S√©parateurs sp√©cifiques: ARTICLE, Section, Chapitre
   - Nettoyage des fronti√®res (d√©but/fin de chunks)
   - Skip des chunks trop petits (<100 chars)

‚úÖ Phase 4: Validation des citations
   - CitationValidator: d√©tecte les hallucinations
   - Exact match + fuzzy match (90%+)
   - Rapport d√©taill√©: taux d'hallucination, citations invalides
   - Int√©gr√© dans le streaming RAG

‚úÖ Phase 5: M√©tadonn√©es enrichies
   - page: num√©ro de page (r√©el ou physique)
   - page_extracted: True si extrait du contenu
   - physical_position: position dans le PDF
   - section: titre de section
   - document_name, document_type

üéØ R√âSULTATS ATTENDUS:
   - Pages: 95%+ de pr√©cision (vs 40% avant)
   - Sections: 80%+ d√©tect√©es (vs 20% avant)
   - Citations: <1% hallucinations (vs 5% avant)
   - Chunking: <5% chunks avec fronti√®res incorrectes

üìù PROCHAINES √âTAPES:
   1. Reprocesser tous les documents avec les nouvelles am√©liorations
   2. Tester avec des questions connues
   3. V√©rifier les citations manuellement
   4. Ajuster les seuils si n√©cessaire
    """)


if __name__ == "__main__":
    print("\n" + "üîç " + "="*76 + " üîç")
    print("           TESTS DES AM√âLIORATIONS RAG")
    print("üîç " + "="*76 + " üîç")
    
    try:
        test_page_extraction()
        test_section_detection()
        test_chunk_quality()
        test_metadata_enrichment()
        print_summary()
        
        print("\n‚úÖ Tous les tests sont termin√©s!")
        
    except Exception as e:
        print(f"\n‚ùå Erreur lors des tests: {e}")
        import traceback
        traceback.print_exc()
    
    print("\n" + "="*80)
