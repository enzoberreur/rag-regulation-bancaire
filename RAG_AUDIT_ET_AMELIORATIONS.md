# üîç AUDIT RAG & PLAN D'AM√âLIORATION

**Date:** 4 novembre 2025  
**Syst√®me:** RAG Banking Compliance Assistant

---

## üìä √âTAT ACTUEL DU SYST√àME

### ‚úÖ Ce qui fonctionne bien

1. **Architecture solide**
   - 8 documents, 642 chunks (moyenne: 80 chunks/doc)
   - Embeddings OpenAI text-embedding-3-small (1536 dimensions)
   - Reranking avec cross-encoder ms-marco-MiniLM-L-6-v2
   - Chunking s√©mantique avec RecursiveCharacterTextSplitter

2. **M√©tadonn√©es pr√©sentes**
   - Document name ‚úÖ
   - Page number ‚úÖ
   - Section titles (parfois) ‚úÖ
   - Token count ‚úÖ

3. **Pipeline RAG complet**
   - Query reformulation ‚úÖ
   - Vector search (16 chunks initiaux) ‚úÖ
   - Reranking (8 meilleurs chunks) ‚úÖ
   - Hybrid mode (documents + expert knowledge) ‚úÖ

---

## üêõ PROBL√àMES IDENTIFI√âS

### 1. ‚ùå **PROBL√àME CRITIQUE: Num√©ros de pages inexacts**

**Sympt√¥me:** Le LLM cite "page 4" mais le texte est ailleurs

**Cause racine:** 
- Le syst√®me utilise `enumerate(reader.pages, start=1)` qui donne la **position physique dans le PDF**
- Mais les documents r√©glementaires ont souvent:
  - Pages de garde (non num√©rot√©es)
  - Tables des mati√®res (num√©rot√©es i, ii, iii)
  - Le contenu principal commence √† "page 1" physique = page 3 ou 4 du PDF

**Exemple:**
```
PDF physique:  [Couverture] [Sommaire] [Page 1 contenu] [Page 2 contenu]
Position:           1            2            3                4
Num√©ro r√©el:       -            -            1                2
```

**Impact:** Citations incorrectes, perte de confiance de l'utilisateur

---

### 2. ‚ö†Ô∏è **D√©tection de sections insuffisante**

**√âtat actuel:** Seulement 1 chunk sur 5 a un titre de section d√©tect√©

**Patterns actuels d√©tect√©s:**
```python
r'^(ARTICLE|Article|CHAPITRE|Chapitre|SECTION|Section|TITRE|Titre)\s+[IVX\d]+'
r'^[IVX\d]+\.\s+[A-Z]'
r'^[IVX\d]+\.[IVX\d]+'
r'^[A-Z][A-Z\s]{5,}$'
```

**Probl√®me:** Beaucoup de sections r√©glementaires ne matchent pas ces patterns:
- "Introduction"
- "Annexe A - D√©finitions"
- "Partie 1 : Cadre g√©n√©ral"
- "6.2. Dispositif de contr√¥le des risques"

---

### 3. ‚ö†Ô∏è **Chunking pourrait √™tre am√©lior√©**

**Configuration actuelle:**
```python
chunk_size=1050 caract√®res  # ~800-900 tokens
chunk_overlap=150 caract√®res  # ~120 tokens
```

**Probl√®mes:**
- Taille variable (735 √† 980 tokens observ√©s) ‚Üí difficile √† pr√©dire
- Overlap trop faible (14%) ‚Üí risque de perdre du contexte entre chunks
- Pas de respect des fronti√®res de sections

---

### 4. ‚ö†Ô∏è **Prompts pourraient √™tre plus stricts**

**Probl√®me actuel:** Le LLM peut paraphraser au lieu de citer exactement
- Prompt dit: "VERBATIM quote" mais LLM traduit parfois
- Exemple: "Tier 1 capital" ‚Üí "fonds propres de cat√©gorie 1"

---

### 5. ‚ÑπÔ∏è **Pas de v√©rification post-g√©n√©ration**

**Manque:** Aucun syst√®me pour v√©rifier que les citations sont correctes apr√®s g√©n√©ration

---

## üöÄ PLAN D'AM√âLIORATION PRIORITAIRE

### üî¥ PRIORIT√â 1: Extraction correcte des num√©ros de page

**Solution:** Parser le num√©ro de page depuis le contenu du PDF

```python
def _extract_real_page_number(self, page_content: str) -> Optional[int]:
    """
    Extrait le vrai num√©ro de page depuis le contenu (footer/header).
    
    Patterns courants:
    - "Page 5"
    - "5/45"
    - "- 5 -"
    - "CRD4 | Page 5"
    """
    import re
    
    # Prendre les derni√®res lignes (footer) et premi√®res lignes (header)
    lines = page_content.strip().split('\n')
    candidates = lines[:3] + lines[-3:]  # 3 premi√®res + 3 derni√®res lignes
    
    for line in candidates:
        line = line.strip()
        
        # Pattern 1: "Page X" ou "PAGE X"
        match = re.search(r'\bPAGE\s+(\d+)\b', line, re.IGNORECASE)
        if match:
            return int(match.group(1))
        
        # Pattern 2: "X/Y" (page X sur Y)
        match = re.search(r'\b(\d+)\s*/\s*\d+\b', line)
        if match:
            return int(match.group(1))
        
        # Pattern 3: "- X -"
        match = re.search(r'-\s*(\d+)\s*-', line)
        if match:
            return int(match.group(1))
        
        # Pattern 4: Juste un nombre isol√© (risqu√©)
        if re.match(r'^\d+$', line):
            return int(line)
    
    return None
```

**Fallback:** Si pas de num√©ro trouv√©, utiliser la position physique mais ajouter un flag:
```python
{
    "page": physical_position,
    "page_extracted": True/False,
    "page_note": "Position dans le PDF, pas le num√©ro r√©el"
}
```

---

### üî¥ PRIORIT√â 2: Am√©liorer la d√©tection de sections

**Ajouter plus de patterns:**

```python
def _detect_section_title(self, text: str) -> Optional[str]:
    """D√©tecte les titres de sections avec patterns √©tendus."""
    import re
    
    first_lines = text.strip().split('\n')[:5]  # 5 au lieu de 3
    
    for line in first_lines:
        line = line.strip()
        if not line or len(line) < 3:
            continue
        
        # Pattern 1: Num√©rotation classique
        if re.match(r'^[IVX\d]+[\.\)]\s+[A-Z]', line):
            return line[:150]
        
        # Pattern 2: Mots-cl√©s de section
        section_keywords = [
            'ARTICLE', 'CHAPITRE', 'SECTION', 'TITRE', 'PARTIE',
            'ANNEXE', 'APPENDIX', 'INTRODUCTION', 'CONCLUSION',
            'D√âFINITIONS', 'DEFINITIONS', 'GLOSSAIRE', 'GLOSSARY'
        ]
        if any(kw in line.upper() for kw in section_keywords):
            return line[:150]
        
        # Pattern 3: Ligne en majuscules (titre)
        if len(line) > 10 and line.isupper() and not line.endswith('.'):
            return line[:150]
        
        # Pattern 4: Format "X.Y.Z Titre"
        if re.match(r'^\d+(\.\d+)*\s+[A-Z]', line):
            return line[:150]
    
    return None
```

---

### üü† PRIORIT√â 3: Optimiser le chunking

**Nouvelle strat√©gie:**

```python
# 1. Augmenter l'overlap
chunk_overlap = 200  # 19% au lieu de 14%

# 2. Utiliser des s√©parateurs plus intelligents
separators = [
    "\n\n\n",           # Sections multiples
    "\n\n",             # Paragraphes
    "\nARTICLE ",       # D√©but d'article
    "\nSection ",       # D√©but de section
    "\n\n",             # Double saut
    "\n",               # Simple saut
    ". ",               # Fin de phrase
    " ",                # Espace
    ""                  # Caract√®re
]

# 3. Ajouter une post-processing pour √©viter de couper en plein milieu
def _clean_chunk_boundaries(self, chunk: str) -> str:
    """Nettoie les fronti√®res de chunk."""
    # Si le chunk commence au milieu d'une phrase, supprimer le d√©but
    if not chunk[0].isupper() and '.' in chunk:
        chunk = chunk[chunk.index('.') + 1:].strip()
    
    # Si le chunk finit au milieu d'une phrase, supprimer la fin
    if not chunk.endswith(('.', '!', '?', '\n')):
        last_period = chunk.rfind('.')
        if last_period > len(chunk) * 0.7:  # Garder au moins 70%
            chunk = chunk[:last_period + 1]
    
    return chunk.strip()
```

---

### üü† PRIORIT√â 4: Renforcer les prompts anti-hallucination

**Modifications:**

```python
SYSTEM_PROMPT = """[...]

**R√àGLE ABSOLUE POUR LES CITATIONS:**

Avant d'utiliser <mark data-source="...">texte</mark>, fais cette v√©rification en 3 √©tapes:

1. **CHERCHER**: Parcours le CONTEXT ci-dessus, lis chaque [Source N: ...]
2. **COMPARER**: Le texte que tu veux citer est-il MOT-√Ä-MOT dans une source?
3. **D√âCIDER**: 
   - OUI, identique ‚Üí Utilise <mark>
   - NON, similaire ‚Üí √âcris normalement SANS <mark>
   - NON, manquant ‚Üí Mentionne "Les documents fournis ne contiennent pas..."

**Exemples INTERDITS:**
‚ùå Source dit "Tier 1 capital ratio" ‚Üí TU NE PEUX PAS √©crire <mark>ratio de fonds propres Tier 1</mark>
‚ùå Source dit "4.5%" ‚Üí TU NE PEUX PAS √©crire <mark>quatre virgule cinq pour cent</mark>
‚ùå Tu connais la r√©ponse mais elle n'est pas dans le CONTEXT ‚Üí PAS de <mark>

**Exemples AUTORIS√âS:**
‚úÖ Source dit "Le ratio CET1 minimum est de 4,5%" ‚Üí <mark data-source="...">Le ratio CET1 minimum est de 4,5%</mark>
‚úÖ Pas dans CONTEXT ‚Üí "Le ratio de levier compare les fonds propres Tier 1 √† l'exposition totale (cette information ne figure pas dans les documents fournis)."
"""
```

---

### üü° PRIORIT√â 5: Ajouter une v√©rification post-g√©n√©ration

**Nouveau service `CitationValidator`:**

```python
class CitationValidator:
    """Valide que les citations sont correctes."""
    
    async def validate_response(
        self, 
        response_text: str, 
        context_chunks: List[DocumentChunk]
    ) -> Dict[str, any]:
        """
        V√©rifie que toutes les citations sont dans le contexte.
        
        Returns:
            {
                "is_valid": bool,
                "invalid_citations": List[str],
                "warnings": List[str]
            }
        """
        import re
        from difflib import SequenceMatcher
        
        # Extraire toutes les citations
        citations = re.findall(r'<mark[^>]*>(.+?)</mark>', response_text, re.DOTALL)
        
        invalid = []
        warnings = []
        
        for citation in citations:
            # Nettoyer le texte
            citation_clean = citation.strip()
            
            # Chercher dans les chunks
            found = False
            best_match_ratio = 0
            
            for chunk in context_chunks:
                # Exact match
                if citation_clean in chunk.content:
                    found = True
                    break
                
                # Fuzzy match (90%+)
                ratio = SequenceMatcher(None, citation_clean, chunk.content).ratio()
                best_match_ratio = max(best_match_ratio, ratio)
                
                if ratio > 0.90:
                    found = True
                    if ratio < 0.98:
                        warnings.append(f"Citation approximative: {citation_clean[:50]}... (match: {ratio:.1%})")
                    break
            
            if not found:
                invalid.append(citation_clean[:100])
        
        return {
            "is_valid": len(invalid) == 0,
            "invalid_citations": invalid,
            "warnings": warnings,
            "total_citations": len(citations),
            "best_match_ratio": best_match_ratio
        }
```

**Int√©gration dans le stream:**

```python
# Apr√®s g√©n√©ration, avant d'envoyer au frontend
validation = await self.citation_validator.validate_response(normalized_content, chunks)

if not validation["is_valid"]:
    print(f"‚ö†Ô∏è HALLUCINATION D√âTECT√âE: {len(validation['invalid_citations'])} citations invalides")
    for invalid in validation["invalid_citations"]:
        print(f"   - {invalid}")
    
    # Option 1: Supprimer les <mark> invalides
    # Option 2: Ajouter un avertissement au frontend
    # Option 3: R√©g√©n√©rer avec un prompt plus strict
```

---

### üü¢ PRIORIT√â 6: Am√©liorer les m√©triques de qualit√©

**Ajouter des m√©triques avanc√©es:**

```python
class RAGMetrics:
    """M√©triques de qualit√© du RAG."""
    
    def calculate_metrics(
        self,
        query: str,
        chunks: List[DocumentChunk],
        response: str,
        validation: Dict
    ) -> Dict[str, any]:
        """Calcule des m√©triques compl√®tes."""
        
        return {
            # Retrieval
            "chunks_retrieved": len(chunks),
            "unique_documents": len(set(c.document_id for c in chunks)),
            "avg_chunk_relevance": sum(scores) / len(scores),
            "page_coverage": list(set(c.chunk_metadata.get("page") for c in chunks)),
            
            # Generation
            "response_length": len(response),
            "citations_count": validation["total_citations"],
            "citations_valid": validation["is_valid"],
            "hallucination_risk": 1.0 - (len(validation["invalid_citations"]) / max(validation["total_citations"], 1)),
            
            # Quality
            "response_coherence": self._calculate_coherence(response),
            "context_utilization": self._calculate_context_usage(response, chunks),
        }
```

---

## üìã CHECKLIST D'IMPL√âMENTATION

### Phase 1: Corrections critiques (1-2h)
- [ ] Impl√©menter `_extract_real_page_number()` dans `TextExtractor`
- [ ] Tester sur 3-4 documents diff√©rents
- [ ] Ajouter fallback pour pages non trouv√©es
- [ ] Am√©liorer `_detect_section_title()` avec patterns √©tendus

### Phase 2: Am√©lioration du chunking (1h)
- [ ] Augmenter `chunk_overlap` √† 200
- [ ] Ajouter s√©parateurs sp√©cifiques (ARTICLE, Section, etc.)
- [ ] Impl√©menter `_clean_chunk_boundaries()`
- [ ] Reprocesser tous les documents

### Phase 3: Validation (2h)
- [ ] Cr√©er `CitationValidator` service
- [ ] Int√©grer dans le streaming
- [ ] Ajouter logging des citations invalides
- [ ] D√©cider de la strat√©gie (supprimer/avertir/r√©g√©n√©rer)

### Phase 4: Prompts (30min)
- [ ] Renforcer le SYSTEM_PROMPT avec v√©rification en 3 √©tapes
- [ ] Ajouter exemples INTERDITS/AUTORIS√âS
- [ ] Tester avec questions connues

### Phase 5: M√©triques (1h)
- [ ] Cr√©er `RAGMetrics` service
- [ ] Ajouter m√©triques avanc√©es au frontend
- [ ] Logger les m√©triques pour analyse

---

## üéØ R√âSULTATS ATTENDUS

### Avant am√©lioration
- ‚ùå Num√©ros de pages incorrects (position physique)
- ‚ö†Ô∏è Citations approximatives (paraphrases)
- ‚ö†Ô∏è Sections mal d√©tect√©es (1/5 seulement)
- ‚ÑπÔ∏è Pas de validation des citations

### Apr√®s am√©lioration
- ‚úÖ Num√©ros de pages r√©els (extraits du contenu)
- ‚úÖ Citations exactes (v√©rifi√©es post-g√©n√©ration)
- ‚úÖ Sections bien d√©tect√©es (4/5 minimum)
- ‚úÖ Validation automatique + alertes hallucination

---

## üìä M√âTRIQUES DE SUCC√àS

| M√©trique | Avant | Objectif | Comment mesurer |
|----------|-------|----------|-----------------|
| Page accuracy | 40% | 95% | Test sur 20 citations al√©atoires |
| Citation exactitude | 70% | 95% | Validation automatique |
| Section d√©tection | 20% | 80% | % chunks avec section |
| Hallucination rate | 5% | <1% | Citations invalides / total |
| User trust score | 6/10 | 9/10 | Feedback utilisateurs |

---

## üîÑ CYCLE D'AM√âLIORATION CONTINUE

1. **Monitoring:** Logger toutes les citations + validation
2. **Analyse:** Review hebdomadaire des hallucinations
3. **Ajustement:** Affiner prompts et patterns
4. **A/B Testing:** Tester nouvelles strat√©gies
5. **Feedback loop:** Int√©grer retours utilisateurs

---

**Prochaine √©tape:** Impl√©menter Phase 1 (extraction pages r√©elles) üöÄ
